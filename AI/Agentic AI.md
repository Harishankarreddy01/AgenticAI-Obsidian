[[LLM]] ? [[RAG]] ? [[Agents]] ? [[MCP]]? [[Certifications]] ?


Machine learning is fundamentally about designing models that learn patterns from data rather than relying on prescribed rules.

Foundational ML topics include supervised, unsupervised, and reinforcement learning; each offers different approaches to pattern recognition and decision-making. For example, supervised learning uses labeled datasets to train models for classification or regression tasks, while reinforcement learning drives agents to learn optimal actions based on reward feedback (3.1). In addition, deep learning has emerged as a powerful subfield that leverages multi-layered neural networks to solve complex tasks across domains such as computer vision, natural language processing, and robotics (4.1).


At the highest level, the agentic AI stack can be conceptualized as a layered architecture consisting of:  a) A foundational layer containing large language models (LLMs) or other pre-trained models that serve as the “brain.”  b) Intermediate layers for memory management, which include short-term context buffers and long-term persistent storage to maintain continuity.  c) Reasoning and planning modules that decompose complex tasks into manageable subtasks using methods like chain-of-thought reasoning and subgoal extraction.  d) Action and tool integration components that enable the system to interact with the external world—by calling APIs, executing code, or interfacing with sensors and human experts.  e) Orchestration components that manage multi-agent interactions, coordination, and dynamic feedback loops (7.1). This structure enables agentic AI systems to flexibly switch between autonomous behavior and human-in-the-loop operation for tasks that require both speed and expertise (8.1).





